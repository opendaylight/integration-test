{
  "comments": [
    {
      "key": {
        "uuid": "1d734c16_35a7b1ed",
        "filename": "csit/suites/openstack/clustering/ha_l3_block_port.robot",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 2264
      },
      "writtenOn": "2018-09-13T15:28:11Z",
      "side": 1,
      "message": "I might be reading this wrong, but at this point we have\nodl3 and old1 that should be syncing to each other right?",
      "range": {
        "startLine": 174,
        "startChar": 4,
        "endLine": 174,
        "endChar": 141
      },
      "revId": "69781baf8cee2f5bb594ae3229bf8648dbdb1b95",
      "serverId": "7fc14799-209e-464c-9743-7a06c2c21a81",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "49601c9a_e85e69c5",
        "filename": "csit/suites/openstack/clustering/ha_l3_block_port.robot",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 7650
      },
      "writtenOn": "2018-09-13T15:54:53Z",
      "side": 1,
      "message": "From a look at ClusterManagement.Check_Cluster_Is_In_Sync it seems it iterates over all members of the cluster, regardless of their expected status, and fails if they aren\u0027t. The third controller is still isolated at this stage, so it won\u0027t be in sync and the check will fail",
      "parentUuid": "1d734c16_35a7b1ed",
      "range": {
        "startLine": 174,
        "startChar": 4,
        "endLine": 174,
        "endChar": 141
      },
      "revId": "69781baf8cee2f5bb594ae3229bf8648dbdb1b95",
      "serverId": "7fc14799-209e-464c-9743-7a06c2c21a81",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "b49c0a67_fb702dee",
        "filename": "csit/suites/openstack/clustering/ha_l3_block_port.robot",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 773
      },
      "writtenOn": "2018-09-17T15:32:46Z",
      "side": 1,
      "message": "In this state it may never sync until both are brought back. Something I just found out, if two members are taken down then both have to be brought back. Something in the way akka works. When I modified the other ha tests to do graceful stop and start I found this. Take odl1 and odl2 down. bring back odl1 - the cluster will not sync until odl2 comes back.",
      "parentUuid": "49601c9a_e85e69c5",
      "range": {
        "startLine": 174,
        "startChar": 4,
        "endLine": 174,
        "endChar": 141
      },
      "revId": "69781baf8cee2f5bb594ae3229bf8648dbdb1b95",
      "serverId": "7fc14799-209e-464c-9743-7a06c2c21a81",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ebd3f94e_721f6fb5",
        "filename": "csit/suites/openstack/clustering/ha_l3_block_port.robot",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 2264
      },
      "writtenOn": "2018-09-17T15:38:44Z",
      "side": 1,
      "message": "really? this doesn\u0027t sound right to me, but maybe there\nis a good reason?",
      "parentUuid": "b49c0a67_fb702dee",
      "range": {
        "startLine": 174,
        "startChar": 4,
        "endLine": 174,
        "endChar": 141
      },
      "revId": "69781baf8cee2f5bb594ae3229bf8648dbdb1b95",
      "serverId": "7fc14799-209e-464c-9743-7a06c2c21a81",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "caaa5d65_def4878a",
        "filename": "csit/suites/openstack/clustering/ha_l3_block_port.robot",
        "patchSetId": 2
      },
      "lineNbr": 174,
      "author": {
        "id": 2264
      },
      "writtenOn": "2018-09-19T17:21:19Z",
      "side": 1,
      "message": "ok after learning what we\u0027ve learned I think this\npatch is right to merge.",
      "parentUuid": "ebd3f94e_721f6fb5",
      "range": {
        "startLine": 174,
        "startChar": 4,
        "endLine": 174,
        "endChar": 141
      },
      "revId": "69781baf8cee2f5bb594ae3229bf8648dbdb1b95",
      "serverId": "7fc14799-209e-464c-9743-7a06c2c21a81",
      "unresolved": false
    }
  ]
}